{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34166840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13803e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset.pickle\", \"rb\") as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38e419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_embedding = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7584192",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../numberbatch-en.txt\", \"r\", encoding=\"utf8\") as fp:\n",
    "    line = fp.readline()\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        line_tokens = line.split(\" \")\n",
    "        word = line_tokens[0]\n",
    "        emb = [float(num) for num in line_tokens[1:]]\n",
    "        word_to_embedding[word.strip()] = emb\n",
    "        line = fp.readline()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509acdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"id_to_word\"] = {wid: word for word, wid in dataset[\"word_to_id\"].items()}\n",
    "dataset[\"id_to_word_relation\"] = {rid: relation for relation, rid in dataset[\"word_relation_to_id\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b36c02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['entity_kg_clean', 'entity_to_id', 'movie_ids', 'relation_counts', 'relation_to_id', 'word_kg_clean', 'word_relation_to_id', 'word_to_id', 'id_to_entity', 'id_to_relation', 'entity_to_edge', 'id_to_word', 'id_to_word_relation'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4d51b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118479"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"word_kg_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9533e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91326/91326 [00:01<00:00, 66267.76it/s]\n"
     ]
    }
   ],
   "source": [
    "wid_to_new_wids = {}\n",
    "words = list(dataset[\"word_to_id\"].keys())\n",
    "for word in tqdm(words):\n",
    "    wid = dataset[\"word_to_id\"][word]\n",
    "    word = word.split(\"/\")[3]\n",
    "    if \"_\" in word:\n",
    "        for w in word.split(\"_\"):\n",
    "            if w not in word_to_embedding:\n",
    "                continue\n",
    "            if w in dataset[\"word_to_id\"]:\n",
    "                new_wid = dataset[\"word_to_id\"][w]\n",
    "            else:\n",
    "                new_wid = len(dataset[\"word_to_id\"]) + 1\n",
    "                dataset[\"word_to_id\"][w] = new_wid\n",
    "                dataset[\"id_to_word\"][new_wid] = w\n",
    "            if wid not in wid_to_new_wids:\n",
    "                wid_to_new_wids[wid] = set()\n",
    "            wid_to_new_wids[wid].add(new_wid)\n",
    "    else:\n",
    "        if word in dataset[\"word_to_id\"]:\n",
    "            new_wid = dataset[\"word_to_id\"][word]\n",
    "        else:\n",
    "            new_wid = len(dataset[\"word_to_id\"]) + 1\n",
    "            dataset[\"word_to_id\"][word] = new_wid\n",
    "            dataset[\"id_to_word\"][new_wid] = word\n",
    "        if wid not in wid_to_new_wids:\n",
    "            wid_to_new_wids[wid] = set()\n",
    "        wid_to_new_wids[wid].add(new_wid)\n",
    "########################        \n",
    "for wid in wid_to_new_wids:\n",
    "    word = dataset[\"id_to_word\"].pop(wid)\n",
    "    dataset[\"word_to_id\"].pop(word)\n",
    "#########################        \n",
    "num_edges = len(dataset[\"word_kg_clean\"])\n",
    "for i in range(num_edges):\n",
    "    w1id, rid, w2id = dataset[\"word_kg_clean\"][i]\n",
    "    new_w1s = set([w1id])\n",
    "    if w1id in wid_to_new_wids:\n",
    "        new_w1s = wid_to_new_wids[w1id]\n",
    "    new_w2s = set([w2id])\n",
    "    if w2id in wid_to_new_wids:\n",
    "        new_w2s = wid_to_new_wids[w2id]\n",
    "    dataset[\"word_kg_clean\"][i] = None\n",
    "    for new_w1 in new_w1s:\n",
    "        for new_w2 in new_w2s:\n",
    "            dataset[\"word_kg_clean\"].append((new_w1, rid, new_w2))\n",
    "dataset[\"word_kg_clean\"] = [edge for edge in dataset[\"word_kg_clean\"] if edge is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c6f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5773\n"
     ]
    }
   ],
   "source": [
    "words_to_remove = set()\n",
    "for word in dataset[\"word_to_id\"]:\n",
    "    if word.startswith(\"/c/en\") or word not in word_to_embedding:\n",
    "        words_to_remove.add(dataset[\"word_to_id\"][word])\n",
    "###############\n",
    "for wid in words_to_remove:\n",
    "    word = dataset[\"id_to_word\"].pop(wid)\n",
    "    dataset[\"word_to_id\"].pop(word)\n",
    "print(len(words_to_remove))\n",
    "##############\n",
    "num_edges = len(dataset[\"word_kg_clean\"])\n",
    "for i in range(num_edges):\n",
    "    w1id, rid, w2id = dataset[\"word_kg_clean\"][i]\n",
    "    if w1id in words_to_remove:\n",
    "        dataset[\"word_kg_clean\"][i] = None\n",
    "    if w2id in words_to_remove:\n",
    "        dataset[\"word_kg_clean\"][i] = None\n",
    "dataset[\"word_kg_clean\"] = [edge for edge in dataset[\"word_kg_clean\"] if edge is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08792453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6000324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"word_kg_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74694e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"word_to_embedding\"] = word_to_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8041737",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wid = 1\n",
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "relation_to_id = {}\n",
    "id_to_relation = {}\n",
    "for i in range(len(dataset[\"word_kg_clean\"])):\n",
    "    w1id, rid, w2id = dataset[\"word_kg_clean\"][i]\n",
    "    w1 = dataset[\"id_to_word\"][w1id]\n",
    "    w2 = dataset[\"id_to_word\"][w2id]\n",
    "    r = dataset[\"id_to_word_relation\"][rid]\n",
    "    if w1 in word_to_id:\n",
    "        new_w1id = word_to_id[w1]\n",
    "    else:\n",
    "        new_w1id = len(word_to_id) + 1\n",
    "        word_to_id[w1] = new_w1id\n",
    "        id_to_word[new_w1id] = w1\n",
    "    \n",
    "    if w2 in word_to_id:\n",
    "        new_w2id = word_to_id[w2]\n",
    "    else:\n",
    "        new_w2id = len(word_to_id) + 1\n",
    "        word_to_id[w2] = new_w2id\n",
    "        id_to_word[new_w2id] = w2\n",
    "        \n",
    "    if r in relation_to_id:\n",
    "        new_rid = relation_to_id[r]\n",
    "    else:\n",
    "        new_rid = len(relation_to_id) + 1\n",
    "        relation_to_id[r] = new_rid\n",
    "        id_to_relation[new_rid] = r  \n",
    "    dataset[\"word_kg_clean\"][i] = (new_w1id, new_rid, new_w2id)\n",
    "dataset[\"word_to_id\"] = word_to_id\n",
    "dataset[\"id_to_word\"] = id_to_word\n",
    "dataset[\"word_relation_to_id\"] = relation_to_id\n",
    "dataset[\"id_to_word_relation\"] = id_to_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97f4c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dataset[\"word_to_id\"]:\n",
    "    if word not in word_to_embedding:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd128296",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset_word_cleaned.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(dataset, fp)\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2b829f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chat]",
   "language": "python",
   "name": "conda-env-chat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
