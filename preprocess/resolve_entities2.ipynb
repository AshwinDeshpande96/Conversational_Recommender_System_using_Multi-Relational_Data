{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ce5b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4b005bb",
   "metadata": {},
   "source": [
    "with open(\"../dataset2.pickle\", \"rb\") as fp:\n",
    "    dataset = pickle.load(fp)\n",
    "    fp.close()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2647f5f8",
   "metadata": {},
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0f968ca",
   "metadata": {},
   "source": [
    "def get_dbpedia_link(ent):\n",
    "    # time.sleep(1)\n",
    "    try:\n",
    "        obj = requests.get(\n",
    "            f\"https://lookup.dbpedia.org/api/search/KeywordSearch?format=JSON&QueryString={ent}\")\n",
    "        data = json.loads(obj.content)\n",
    "        for doc in data.get(\"docs\", []):\n",
    "            dbpedia_link = doc.get(\"resource\")\n",
    "            score = float(doc.get(\"score\")[0])\n",
    "            if dbpedia_link and score > 2000:\n",
    "#                 print(ent, dbpedia_link, score)\n",
    "                return dbpedia_link[0]\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ebc50f8",
   "metadata": {},
   "source": [
    "def decompound_entities(entities):\n",
    "    normalized_entities = []\n",
    "    for ent in entities:\n",
    "        ent = ent.strip()\n",
    "        new_ent = get_dbpedia_link(ent)\n",
    "        if new_ent is None:\n",
    "            new_ent = ent\n",
    "        normalized_entities.append(new_ent)\n",
    "    return normalized_entities              "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad31ee0d",
   "metadata": {},
   "source": [
    "memo = {}\n",
    "def resolve_entity(entity):\n",
    "    if entity in memo:\n",
    "        return memo[entity]\n",
    "    result = []\n",
    "    if not isinstance(entity, str):\n",
    "        result = []\n",
    "    elif re.match(\"[0-9]{4}\\-[0-9]{2}\\-[0-9]{2}\", entity):\n",
    "        result = []\n",
    "    elif \"dbpedia\" in entity:\n",
    "        result = [entity]\n",
    "    elif \",\" in entity:\n",
    "        result = decompound_entities(entity.split(\",\"))\n",
    "    elif \"/\" in entity:\n",
    "        result = decompound_entities(entity.split(\"/\"))\n",
    "    elif \"\\n\" in entity:\n",
    "        result = decompound_entities(entity.split(\"\\n\"))\n",
    "    else:\n",
    "        result = decompound_entities([entity])\n",
    "    memo[entity] = result\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8b2889e",
   "metadata": {},
   "source": [
    "columns = [\"entity1\", \"relation\", \"entity2\"]\n",
    "kgdf = pd.DataFrame(columns=columns)\n",
    "kg = []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9143475c",
   "metadata": {},
   "source": [
    "for e1id, rid, e2id in tqdm(dataset[\"entity_kg_clean\"]):\n",
    "    if e1id not in dataset[\"id_to_entity\"]:\n",
    "        continue\n",
    "    if e2id not in dataset[\"id_to_entity\"]:\n",
    "        continue\n",
    "    e1 = dataset[\"id_to_entity\"][e1id]\n",
    "    e1s = resolve_entity(e1)\n",
    "    r = dataset[\"id_to_relation\"][rid]\n",
    "    e2 = dataset[\"id_to_entity\"][e2id]\n",
    "    e2s = resolve_entity(e2)\n",
    "    for e1_elem in e1s:\n",
    "        for e2_elem in e2s:\n",
    "            row = [e1_elem, r, e2_elem]\n",
    "            if row in kg:\n",
    "                continue\n",
    "            kg.append(row)\n",
    "            row = dict(zip(columns, row))\n",
    "            kgdf = kgdf.append(row, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "eebaf12a",
   "metadata": {},
   "source": [
    "len(kgdf.iloc[123484].entity2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc18189a",
   "metadata": {},
   "source": [
    "kgdf.to_pickle(\"kgdf.pickle\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fa84fb9",
   "metadata": {},
   "source": [
    "from graphembedding.playground import load_github\n",
    "from graphembedding import complEx, transE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12f51d41",
   "metadata": {},
   "source": [
    "node_embedding, edge_embedding = complEx(triplets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2fa86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgdf = pd.read_pickle(\"kgdf.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e8322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgdf[\"entity1\"] = kgdf.entity1.apply(lambda x: x.strip())\n",
    "kgdf[\"relation\"] = kgdf.relation.apply(lambda x: x.strip())\n",
    "kgdf[\"entity2\"] = kgdf.entity2.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1ddac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kgdf_clean = kgdf[~((kgdf[\"entity1\"] == \"\") | (kgdf[\"relation\"] == \"\") | (kgdf[\"entity2\"] == \"\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93614b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = kgdf_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd63d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['http://dbpedia.org/resource/Headhunter_(2009_film)', 'country',\n",
       "       'http://dbpedia.org/resource/Denmark'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67e9eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pykeen==1.0.5\n",
      "  Downloading pykeen-1.0.5-py3-none-any.whl (319 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pykeen==1.0.5) (1.21.5)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting optuna>=2.0.0\n",
      "  Using cached optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "Collecting click-default-group\n",
      "  Using cached click_default_group-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pykeen==1.0.5) (4.63.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pykeen==1.0.5) (1.2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pykeen==1.0.5) (2.27.1)\n",
      "Requirement already satisfied: click in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pykeen==1.0.5) (7.1.2)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting dataclasses-json\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.7.7-py3-none-any.whl (210 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting PyYAML\n",
      "  Using cached PyYAML-6.0-cp37-cp37m-win_amd64.whl (153 kB)\n",
      "Collecting cliff\n",
      "  Using cached cliff-3.10.1-py3-none-any.whl (81 kB)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Using cached SQLAlchemy-1.4.35-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (1.7.3)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from optuna>=2.0.0->pykeen==1.0.5) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from packaging>=20.0->optuna>=2.0.0->pykeen==1.0.5) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pandas>=1.0.0->pykeen==1.0.5) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from pandas>=1.0.0->pykeen==1.0.5) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.0.0->pykeen==1.0.5) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from sqlalchemy>=1.1.0->optuna>=2.0.0->pykeen==1.0.5) (4.8.2)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-1.1.2-cp37-cp37m-win_amd64.whl (101 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.0-py3-none-any.whl (78 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.7.0-py3-none-any.whl (28 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.2.0-py3-none-any.whl (26 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.0-py3-none-any.whl (29 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna>=2.0.0->pykeen==1.0.5) (21.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna>=2.0.0->pykeen==1.0.5) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2-py3-none-any.whl\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna>=2.0.0->pykeen==1.0.5) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna>=2.0.0->pykeen==1.0.5) (3.7.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from colorlog->optuna>=2.0.0->pykeen==1.0.5) (0.4.4)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.15.0-py3-none-any.whl (47 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Collecting MarkupSafe>=0.9.2\n",
      "  Using cached MarkupSafe-2.1.1-cp37-cp37m-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from requests->pykeen==1.0.5) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from requests->pykeen==1.0.5) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from requests->pykeen==1.0.5) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from requests->pykeen==1.0.5) (1.26.9)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from sklearn->pykeen==1.0.5) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from scikit-learn->sklearn->pykeen==1.0.5) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ashwin\\anaconda3\\envs\\chat\\lib\\site-packages (from scikit-learn->sklearn->pykeen==1.0.5) (3.1.0)\n",
      "Installing collected packages: pyreadline3, pyperclip, pbr, MarkupSafe, greenlet, stevedore, sqlalchemy, PyYAML, PrettyTable, mypy-extensions, marshmallow, Mako, importlib-resources, cmd2, autopage, typing-inspect, marshmallow-enum, colorlog, cmaes, cliff, alembic, tabulate, sklearn, optuna, dataclasses-json, click-default-group, pykeen\n",
      "Successfully installed Mako-1.2.0 MarkupSafe-2.1.1 PrettyTable-3.2.0 PyYAML-6.0 alembic-1.7.7 autopage-0.5.0 click-default-group-1.2.2 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 dataclasses-json-0.5.7 greenlet-1.1.2 importlib-resources-5.7.0 marshmallow-3.15.0 marshmallow-enum-1.5.1 mypy-extensions-0.4.3 optuna-2.10.0 pbr-5.8.1 pykeen-1.0.5 pyperclip-1.8.2 pyreadline3-3.4.1 sklearn-0.0 sqlalchemy-1.4.35 stevedore-3.5.0 tabulate-0.8.9 typing-inspect-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pykeen==1.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38d204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\envs\\chat\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['NCBIGENE:11200', 'GENE_PHENOTYPE', 'HP:0009919'],\n",
       "       ['NCBIGENE:2649', 'GENE_EXPRESSED_ANATOMY', 'UBERON:0000059'],\n",
       "       ['NCBIGENE:534', 'GENE_EXPRESSED_ANATOMY', 'UBERON:0000467'],\n",
       "       ...,\n",
       "       ['NCBIGENE:1269', 'GENE_REACTION_GENE', 'NCBIGENE:6376'],\n",
       "       ['NCBIGENE:1785', 'GENE_EXPRESSED_ANATOMY', 'UBERON:0003729'],\n",
       "       ['NCBIGENE:55591', 'GENE_EXPRESSED_ANATOMY', 'UBERON:0002038']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pykeen.datasets import OpenBioLink\n",
    "dataset = OpenBioLink()\n",
    "dataset.training.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9a45f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_kg(df, test_split=0.3, error=50):\n",
    "    epairs = {}\n",
    "    for idx, (e1, e2) in df[[\"entity1\", \"entity2\"]].iterrows():\n",
    "        if (e1, e2) in epairs:\n",
    "            key = (e1, e2)\n",
    "        elif (e2, e1) in epairs:\n",
    "            key = (e2, e1)\n",
    "        else:\n",
    "            key = (e1, e2)\n",
    "            epairs[key] = []\n",
    "        epairs[key].append(idx)\n",
    "    epairs_sorted = {k: (v, len(v)) for k, v in sorted(x.items(), key=lambda item: len(item[1]), reverse=True)}\n",
    "    total_size = df.shape[0]\n",
    "    test_size = test_split*total_size\n",
    "    test_ids = []\n",
    "    for epair, value in epairs_sorted:\n",
    "        ids, ids_len = value\n",
    "        if len(test_ids) > test_size:\n",
    "            break\n",
    "        remaining_size = test_size - len(test_ids)\n",
    "        if ids_len < remaining_size + error:\n",
    "            test_ids += ids\n",
    "    print(len(test_ids))\n",
    "    print(len(set(test_ids)))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d25c4bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8120\\1944920877.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_kg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkgdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8120\\1675227778.py\u001b[0m in \u001b[0;36msplit_kg\u001b[1;34m(df, test_split, error)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mepairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mepairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mepairs_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtotal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "train, test = split_kg(kgdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cefc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:chat]",
   "language": "python",
   "name": "conda-env-chat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
